{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develope a Model to predict if there will be Purchase or not\n",
    "\n",
    "My task here is to recommend the marketing team a better set of possible customers to focus on who have higher chance of purchasing based on given features. Inorder to achieve that, I need to train my ML algorithm on given dataset and train a model based on mapping of input features and target output, which in my case is given set of input feature vectors does a client does a purchase or Not.\n",
    "\n",
    "One thing needs to be clear before I proceed ahead is that my problem statement is a Classification problem, where given training sample I will tune my model to test on unknown samples.\n",
    "\n",
    "I will be breaking the entire working into following stages:\n",
    "\n",
    "1] Read Dataset\n",
    "\n",
    "2] Check Balanced or Imbalanced data (based on target labels)\n",
    "\n",
    "3] Treat the Imbalanced Data (Doing Re-Sampeling)\n",
    "\n",
    "4] Pre-Processing: \n",
    "   - Repair my dataset for any breakdowns or missing values in dataset\n",
    "   - Convert categorical features to numeric\n",
    "\n",
    "5] Spliting the new processed data in to Train-Test data\n",
    "\n",
    "6] Decide on an ML algos for training our Model\n",
    "\n",
    "    6.1] Testing the models\n",
    "    6.2] Evaluating the models\n",
    "\n",
    "7] Plotting the Evaluation Metric of different ML algos\n",
    "\n",
    "Lets start by importing packages and libraries for graph display, I use %inline to show graph in same notebook window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "#import pylab as plb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>E</td>\n",
       "      <td>19.98</td>\n",
       "      <td>5</td>\n",
       "      <td>189.88</td>\n",
       "      <td>9</td>\n",
       "      <td>2305</td>\n",
       "      <td>10</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "      <td>D</td>\n",
       "      <td>15.98</td>\n",
       "      <td>6</td>\n",
       "      <td>68.95</td>\n",
       "      <td>29</td>\n",
       "      <td>609</td>\n",
       "      <td>10</td>\n",
       "      <td>250.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>E</td>\n",
       "      <td>12.29</td>\n",
       "      <td>3</td>\n",
       "      <td>36.00</td>\n",
       "      <td>3</td>\n",
       "      <td>648</td>\n",
       "      <td>U</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>E</td>\n",
       "      <td>21.48</td>\n",
       "      <td>2</td>\n",
       "      <td>26.45</td>\n",
       "      <td>1</td>\n",
       "      <td>3250</td>\n",
       "      <td>U</td>\n",
       "      <td>200.0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>E</td>\n",
       "      <td>15.96</td>\n",
       "      <td>7</td>\n",
       "      <td>13.95</td>\n",
       "      <td>29</td>\n",
       "      <td>873</td>\n",
       "      <td>U</td>\n",
       "      <td>200.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>500.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3 x4     x5  x6      x7  x8    x9 x10    x11  x12  x13     x14  \\\n",
       "0  10  21  28  E  19.98   5  189.88   9  2305  10  500.0    3   31  1000.0   \n",
       "1  10  22  46  D  15.98   6   68.95  29   609  10  250.0    8   16   100.0   \n",
       "2  10  23  38  E  12.29   3   36.00   3   648   U  200.0    4    2   250.0   \n",
       "3   5  20  25  E  21.48   2   26.45   1  3250   U  200.0   14   13   500.0   \n",
       "4  10  17  33  E  15.96   7   13.95  29   873   U  200.0   14   10   500.0   \n",
       "\n",
       "  x15  Purchase  \n",
       "0   A         0  \n",
       "1   B         0  \n",
       "2   A         0  \n",
       "3   B         0  \n",
       "4   A         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('DataScienceChallenge.csv',sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above dataset contains some numerical features whereas some categorical features and a target label as 'Purchase' which has values 0 or 1. \n",
    "\n",
    "- Let's first check if the data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnkjs\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20a7582d358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAE8CAYAAACSMYZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABRAtAEAFEC0AQAUQLQBABTg/wHEzFpSYlryJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set seaborn graph size\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "\n",
    "#plot the graph\n",
    "sns.countplot(x='Purchase',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets consider Purchase == 0 as (Yes purchased) and Purchase == 1 as (Not Purchase)\n",
    "\n",
    "\n",
    "* So the number of records for Purchase are almost <b>90 % </b> of total data and the Not purchase are approx <b>10 % </b>\n",
    "\n",
    "* Hence there is <b>lot of imbalance.</b> Let's confirm it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51448, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchased = df[df.Purchase==0]\n",
    "\n",
    "purchased.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3620, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_purchased = df[df.Purchase==1]\n",
    "\n",
    "not_purchased.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating the Imbalanced Data\n",
    "\n",
    "I will follow the Data Level Approach to treat the Imbalanced Data by using Re-Sampeling technique (Random Under-Sampeling)\n",
    "\n",
    "<b> Random Under-Sampeling - It aims to balance class distribution by randomly eliminating majority class examples. This is done until the majority and minority class instances are balanced out. </b> [1]\n",
    "\n",
    "- So here I will sample random data from purchased section to balance with non_purchased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchased1 = purchased.sample(n=5000,random_state=2)\n",
    "purchased1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data = not_purchased.append(purchased1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8620, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnkjs\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20a76b870b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAE8CAYAAACFExa4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Purchase',data=balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>J</td>\n",
       "      <td>13.89</td>\n",
       "      <td>9</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1231</td>\n",
       "      <td>U</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>J</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>U</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>J</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>U</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>E</td>\n",
       "      <td>19.10</td>\n",
       "      <td>9</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>14</td>\n",
       "      <td>225.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>600.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>K</td>\n",
       "      <td>15.98</td>\n",
       "      <td>4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1229</td>\n",
       "      <td>U</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3 x4     x5  x6     x7  x8    x9 x10    x11  x12  x13    x14 x15  \\\n",
       "0   2  18  49  J  13.89   9   8.45   1  1231   U  250.0   14    5  250.0   A   \n",
       "1   3  18  27  J  14.22   7  23.45   4   832   U  250.0   10    5  500.0   B   \n",
       "2   3  18  27  J  14.22   7  23.45   4  1005   U  250.0   10    5  500.0   B   \n",
       "3   1  17  35  E  19.10   9  13.95   1  1328  14  225.0   14    9  600.0   B   \n",
       "4   2  18  33  K  15.98   4   7.00   1  1229   U  200.0   12    6    0.0   A   \n",
       "\n",
       "   Purchase  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x3</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "      <td>8084.000000</td>\n",
       "      <td>8620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.674594</td>\n",
       "      <td>35.962993</td>\n",
       "      <td>17.289042</td>\n",
       "      <td>5.025870</td>\n",
       "      <td>56.953290</td>\n",
       "      <td>10.865081</td>\n",
       "      <td>957.777030</td>\n",
       "      <td>345.323788</td>\n",
       "      <td>9.107425</td>\n",
       "      <td>12.598724</td>\n",
       "      <td>331.438644</td>\n",
       "      <td>0.419954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.416880</td>\n",
       "      <td>9.381556</td>\n",
       "      <td>4.629677</td>\n",
       "      <td>3.506962</td>\n",
       "      <td>61.449011</td>\n",
       "      <td>11.492276</td>\n",
       "      <td>519.560806</td>\n",
       "      <td>175.495870</td>\n",
       "      <td>4.065774</td>\n",
       "      <td>8.750456</td>\n",
       "      <td>233.765832</td>\n",
       "      <td>0.493580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.960000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.450000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>209.487500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.950000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>19.950000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>75.700000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>62.080000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4380.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x3           x5           x6           x7  \\\n",
       "count  8620.000000  8620.000000  8620.000000  8620.000000  8620.000000   \n",
       "mean      8.674594    35.962993    17.289042     5.025870    56.953290   \n",
       "std       2.416880     9.381556     4.629677     3.506962    61.449011   \n",
       "min       1.000000    20.000000     6.980000     0.000000     3.000000   \n",
       "25%       8.000000    29.000000    13.960000     2.000000    15.450000   \n",
       "50%      10.000000    34.000000    15.980000     5.000000    33.950000   \n",
       "75%      10.000000    40.000000    19.950000     8.000000    75.700000   \n",
       "max      10.000000    75.000000    62.080000    15.000000   800.000000   \n",
       "\n",
       "                x8           x9          x11          x12          x13  \\\n",
       "count  8620.000000  8620.000000  8620.000000  8620.000000  8620.000000   \n",
       "mean     10.865081   957.777030   345.323788     9.107425    12.598724   \n",
       "std      11.492276   519.560806   175.495870     4.065774     8.750456   \n",
       "min       0.000000   280.000000     0.000000     0.000000     1.000000   \n",
       "25%       1.000000   580.000000   209.487500     6.000000     6.000000   \n",
       "50%       5.000000   849.000000   300.000000    10.000000    11.000000   \n",
       "75%      22.000000  1199.000000   500.000000    12.000000    16.000000   \n",
       "max      60.000000  4380.000000  1250.000000    15.000000    48.000000   \n",
       "\n",
       "               x14     Purchase  \n",
       "count  8084.000000  8620.000000  \n",
       "mean    331.438644     0.419954  \n",
       "std     233.765832     0.493580  \n",
       "min       0.000000     0.000000  \n",
       "25%     200.000000     0.000000  \n",
       "50%     250.000000     0.000000  \n",
       "75%     500.000000     1.000000  \n",
       "max    1000.000000     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the statistics for the numerical values\n",
    "balanced_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cell I can observe that feature x2,x4,x10 and x15 contains some non numeric/categorical values.\n",
    "\n",
    "Let's confirm all the unique values from these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18', '17', '20', '22', '15', '16', '21', '19', '24', '23', '26',\n",
       "       '25', '30', 'Unknown', '14', '29', '31'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data['x2'].unique()\n",
    "\n",
    "# here I can see there are some missing values named as 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['J', 'E', 'K', 'H', 'A', 'I', 'G', 'C', 'D', 'B', 'F', nan], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data['x4'].unique() \n",
    "\n",
    "# Here I can see we have nan values in these feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U', '14', '6', '10', '5', '0', '1', '12', '4', '7', '3', '8', '2',\n",
       "       '9', '13', '11'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data['x10'].unique()\n",
    "\n",
    "# here I can see there are some missing values named as 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data['x15'].unique()\n",
    "\n",
    "# here I can see this feature has categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1            0\n",
       "x2            0\n",
       "x3            0\n",
       "x4           21\n",
       "x5            0\n",
       "x6            0\n",
       "x7            0\n",
       "x8            0\n",
       "x9            0\n",
       "x10           0\n",
       "x11           0\n",
       "x12           0\n",
       "x13           0\n",
       "x14         536\n",
       "x15           0\n",
       "Purchase      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many null values are present in our dataframe\n",
    "\n",
    "balanced_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Except these Null values from the above result, there are some other missing values that are designated using other strings like 'U' or 'Unknown' as found from the above cells. Let's replace all these values and bring them to null values using Numpy package built-in function 'np.NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1             0\n",
       "x2            38\n",
       "x3             0\n",
       "x4            21\n",
       "x5             0\n",
       "x6             0\n",
       "x7             0\n",
       "x8             0\n",
       "x9             0\n",
       "x10         3526\n",
       "x11            0\n",
       "x12            0\n",
       "x13            0\n",
       "x14          536\n",
       "x15            0\n",
       "Purchase       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data = balanced_data.replace('U',np.NaN)\n",
    "balanced_data = balanced_data.replace('Unknown',np.NaN)\n",
    "balanced_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from above:\n",
    "\n",
    "- We can see that out of total 8620 records the feature x2,x10,x14 (numeric variables) have missing values.\n",
    "\n",
    "- Even the feature x4 (categorical feature) also have missing values.\n",
    "\n",
    "- It is important to treat these missing values because these missing values can affect power of model and may lead to biased model and also result false/wrong predictions or classification. \n",
    "\n",
    "- In this case , we can choose either doing data imputation or dropping the missing value records or dropping the whole feature.\n",
    "\n",
    "- For x2 and x4 , I will drop these NA values as they are in very less numbers and they wont affect the amount of data.\n",
    "\n",
    "- For x10 and x14 I will replace the NA values using data imputation i.e replacing them with respective mean/median/mode of that specific columns because removing them can cause decrease in amount of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1             0\n",
       "x2             0\n",
       "x3             0\n",
       "x4             0\n",
       "x5             0\n",
       "x6             0\n",
       "x7             0\n",
       "x8             0\n",
       "x9             0\n",
       "x10         3496\n",
       "x11            0\n",
       "x12            0\n",
       "x13            0\n",
       "x14          488\n",
       "x15            0\n",
       "Purchase       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping NA values from x4 and x2 features\n",
    "\n",
    "balanced_data =  balanced_data.dropna(subset=['x4','x2'])\n",
    "balanced_data.reset_index()\n",
    "balanced_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below filling of missing values can be done in multiple ways of data imputation as discussed\n",
    "\n",
    "# lets replace x10 feature by finding the median of its column values\n",
    "balanced_data['x10'] = balanced_data['x10'].fillna((balanced_data['x10'].median()))\n",
    "\n",
    "# lets replace x14 feature by finding the mean of its column values\n",
    "balanced_data['x14'] = balanced_data['x14'].fillna((balanced_data['x14'].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I will transfer all the above pre-processed data to a new dataframe for further processing\n",
    "\n",
    "new_balanced_data=balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1          0\n",
       "x2          0\n",
       "x3          0\n",
       "x4          0\n",
       "x5          0\n",
       "x6          0\n",
       "x7          0\n",
       "x8          0\n",
       "x9          0\n",
       "x10         0\n",
       "x11         0\n",
       "x12         0\n",
       "x13         0\n",
       "x14         0\n",
       "x15         0\n",
       "Purchase    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check again if we have no null/NA values left in our data\n",
    "new_balanced_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>J</td>\n",
       "      <td>13.89</td>\n",
       "      <td>9</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1231</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>J</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>J</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>E</td>\n",
       "      <td>19.10</td>\n",
       "      <td>9</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>14</td>\n",
       "      <td>225.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>600.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>K</td>\n",
       "      <td>15.98</td>\n",
       "      <td>4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1229</td>\n",
       "      <td>9</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3 x4     x5  x6     x7  x8    x9 x10    x11  x12  x13    x14 x15  \\\n",
       "0   2  18  49  J  13.89   9   8.45   1  1231   9  250.0   14    5  250.0   A   \n",
       "1   3  18  27  J  14.22   7  23.45   4   832   9  250.0   10    5  500.0   B   \n",
       "2   3  18  27  J  14.22   7  23.45   4  1005   9  250.0   10    5  500.0   B   \n",
       "3   1  17  35  E  19.10   9  13.95   1  1328  14  225.0   14    9  600.0   B   \n",
       "4   2  18  33  K  15.98   4   7.00   1  1229   9  200.0   12    6    0.0   A   \n",
       "\n",
       "   Purchase  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That is great, looks like I dont have any null values, so I will proceed for converting categorial values to numerical using LabelEncoder\n",
    "\n",
    "Note: This is a optional step just to bring all of our data into single representation. However, it is also possible to proceed with mixed type data. I would like to continue with single representation as I believe I will get good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "SKLPP = preprocessing.LabelEncoder()\n",
    "#THEN COVERTING SPECIFIC CATEGORIAL COLUMNS TO VALUES\n",
    "new_balanced_data.x4 = SKLPP.fit_transform(new_balanced_data.x4)\n",
    "new_balanced_data.x15 = SKLPP.fit_transform(new_balanced_data.x15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>13.89</td>\n",
       "      <td>9</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1231</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>19.10</td>\n",
       "      <td>9</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>14</td>\n",
       "      <td>225.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>15.98</td>\n",
       "      <td>4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1229</td>\n",
       "      <td>9</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4     x5  x6     x7  x8    x9 x10    x11  x12  x13    x14  \\\n",
       "0   2  18  49   9  13.89   9   8.45   1  1231   9  250.0   14    5  250.0   \n",
       "1   3  18  27   9  14.22   7  23.45   4   832   9  250.0   10    5  500.0   \n",
       "2   3  18  27   9  14.22   7  23.45   4  1005   9  250.0   10    5  500.0   \n",
       "3   1  17  35   4  19.10   9  13.95   1  1328  14  225.0   14    9  600.0   \n",
       "4   2  18  33  10  15.98   4   7.00   1  1229   9  200.0   12    6    0.0   \n",
       "\n",
       "   x15  Purchase  \n",
       "0    0         1  \n",
       "1    1         1  \n",
       "2    1         1  \n",
       "3    1         1  \n",
       "4    0         1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Train-Test Split\n",
    "\n",
    "#### So now, I am all set for training the model, a final step before that is splitting the data in to training and testing datasets\n",
    "\n",
    "#### As per standard procedure I will follow a Simple Hold-Out Strategy using 80-20 split, where 80% data is assigned to training sample and 20% to testing and evaluation. \n",
    "\n",
    " - <b>There are other methods like using  Cross Validation, Leave-One-Out or Three-way-hold-out strategy. It necessarily depends on the requirements and the type of data we have. In order to evaluate your model effectively, trial to all these strategies should be given and checked which is perfectly suitable to your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>13.89</td>\n",
       "      <td>9</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1231</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14.22</td>\n",
       "      <td>7</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "      <td>1005</td>\n",
       "      <td>9</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>19.10</td>\n",
       "      <td>9</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1328</td>\n",
       "      <td>14</td>\n",
       "      <td>225.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>15.98</td>\n",
       "      <td>4</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1229</td>\n",
       "      <td>9</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4     x5  x6     x7  x8    x9 x10    x11  x12  x13    x14  x15\n",
       "0   2  18  49   9  13.89   9   8.45   1  1231   9  250.0   14    5  250.0    0\n",
       "1   3  18  27   9  14.22   7  23.45   4   832   9  250.0   10    5  500.0    1\n",
       "2   3  18  27   9  14.22   7  23.45   4  1005   9  250.0   10    5  500.0    1\n",
       "3   1  17  35   4  19.10   9  13.95   1  1328  14  225.0   14    9  600.0    1\n",
       "4   2  18  33  10  15.98   4   7.00   1  1229   9  200.0   12    6    0.0    0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I need to consider first 15 columns which are my features, as X\n",
    "\n",
    "X= new_balanced_data.iloc[:,0:15]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Purchase, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last column is my target label, and hence I am putting it in Y\n",
    "\n",
    "Y = new_balanced_data.iloc[:,15]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me verify the shape of my training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6850, 15), (6850,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1713, 15), (1713,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm training\n",
    "\n",
    "The most important task here is to decide, which algorithm is right for our need, there is no such algorithm which we can call as best. As every algorithm is best in different situation.\n",
    "\n",
    "Given a Supervised Situation, where I need to run a Classification model, several algorithms come to my mind,\n",
    "\n",
    "1] Decision tree\n",
    "\n",
    "2] Logistic Regression\n",
    "\n",
    "3] Random Forest\n",
    "\n",
    "4] Support Vector Machine\n",
    "\n",
    "5] K-Nearest Neighbour\n",
    "\n",
    "6] Neural Networks\n",
    "\n",
    "7] Naive Bayes etc.\n",
    "\n",
    "<b> The best way to decide which algorithm performs best in our case is to run all of these algorithms and select one with highest accuracy. However, I would short list a few which I feel will perform great or which wont. As the data I have is full with numeric values, I feel Logistic Regression, Random Forest, Decision Tree and SVM  would suit more.</b>\n",
    "\n",
    "- As Logistic Regression performs binary classification, It takes linear combination of features and applies non-linear function (sigmoid) to it, so it’s a very small instance of neural network.\n",
    "\n",
    "\n",
    "- Random Forest is an Ensemble model approach of Decision Trees and it is highly scalable and generally used in real worl applications\n",
    "\n",
    "\n",
    "- As Decision Trees are used in Random Forest, I would like to give a try using Decision Trees,\n",
    "\n",
    "\n",
    "- SVM are good on binary target labels, so I will give a try using it\n",
    "\n",
    "\n",
    "- Neural Network always are great to learn at granular level and outperform most generic algorithms however they need huge training data with high diversity. As our training data was looking a bit baised towards '0' class, I performed Random Sampeling and hence the amount of data was reduced according to '1' class label. I feel it wont be ideal to use neural network. \n",
    "\n",
    "\n",
    "- Naive Bayes on the other hand works good if we have categorical variables, where in this data I was not having much and hence converted the available categorical features to numeric feature values.\n",
    "\n",
    "Let us try all this different algos,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.766491535318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81      1005\n",
      "          1       0.74      0.68      0.71       708\n",
      "\n",
      "avg / total       0.76      0.77      0.76      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy\", logistic_accuracy)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.832457676591\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86      1005\n",
      "          1       0.83      0.74      0.79       708\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomforest_accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy\",randomforest_accuracy)\n",
    "print(classification_report(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = dtc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.769410391127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.77      0.80      1005\n",
      "          1       0.70      0.77      0.73       708\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decisionTree_accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy\",decisionTree_accuracy)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.589608873322\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.74      1005\n",
      "          1       1.00      0.01      0.01       708\n",
      "\n",
      "avg / total       0.76      0.59      0.44      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy\",svm_accuracy)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = neigh.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.608289550496\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.70      0.68      1005\n",
      "          1       0.53      0.48      0.50       708\n",
      "\n",
      "avg / total       0.60      0.61      0.61      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy\",knn_accuracy)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Plotting the Metrics (Accuracy) of different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAE8CAYAAAD+N9R0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH6YfgXLFiZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the bar labels\n",
    "bar_labels = ['SVM','Logistic Regression','Random_Forest','Decision Tree','KNN']\n",
    "\n",
    "# Create the x position of the bars and give bar graph parameters\n",
    "N=5\n",
    "x_pos = np.arange(N)\n",
    "\n",
    "# Create the plot bars\n",
    "accuracy_scores=(svm_accuracy,logistic_accuracy,randomforest_accuracy,decisionTree_accuracy,knn_accuracy)\n",
    "\n",
    "#We can plot other performance factors like F1-measures along with Accuracy, therefore we can use subplots.\n",
    "fig, ax =plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Plot a bar graph. \n",
    "plt.bar([p for p in x_pos],# using the data from the mean_values\n",
    "        accuracy_scores, \n",
    "        color='orange'\n",
    "        )\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Classifier Models Comparison Graph')\n",
    "\n",
    "# set axes labels and title\n",
    "ax.set_ylabel('Accuracy %')\n",
    "ax.set_xticks([p for p in x_pos])\n",
    "ax.set_xticklabels(bar_labels)\n",
    "plt.ylim(0.1,1)\n",
    "plt.legend(['Accuracy Scores'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion:\n",
    "\n",
    "- From the above graph, it can be stated that the Ensemble approach using Random Forest algo is the best suit for this data, as it gives pretty good accuracy for the predictions.\n",
    "\n",
    "- On the other hand, SVM and KNN does not perform well\n",
    "\n",
    "- Logistic Regression and Decision Trees performs on the average level.\n",
    "\n",
    "- So I would suggest of using Random Forest for the predictions for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "   \n",
    "   \n",
    "[1] : https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/\n",
    "\n",
    "[2] : https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4\n",
    "\n",
    "[3] : https://hackernoon.com/choosing-the-right-machine-learning-algorithm-68126944ce1f?gi=3a33aea7a918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
